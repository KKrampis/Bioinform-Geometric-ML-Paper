<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.17">
<title>Principles of Artificial Neural Networks and Machine Learning for Bioinformatics Applications</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="article">
<div id="header">
</div>
<div id="content">
<div class="sect1">
<h2 id="_principles_of_artificial_neural_networks_and_machine_learning_for_bioinformatics_applications">Principles of Artificial Neural Networks and Machine Learning for Bioinformatics Applications</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Konstantinos Krampis*<sup>1</sup>, Eric Ross<sup>2</sup>, Olorunseun O. Ogunwobi<sup>1</sup>, Grace Ma,<sup>3</sup> Raja Mazumder,<sup>4</sup> Claudia Wultsch<sup>1</sup></p>
</div>
<div class="paragraph">
<p><sup>1</sup>Belfer Research Facility, Biological Sciences, Hunter College, City University of New York, NY, USA
<sup>2</sup>Fox Chase Cancer Center, Philadephia, PA, USA
<sup>3</sup>Center for Asian Health, Lewis Katz School of Medicine, Temple University, Philadelphia, PA, USA
<sup>4</sup>Biochemistry and Molecular Biology, George Washington University, Washington D.C., USA</p>
</div>
<div class="paragraph">
<p><sup>*</sup>Corresponding Author, <em>kk104@hunter.cuny.edu</em></p>
</div>
<div class="sect3">
<h4 id="_abstract">ABSTRACT</h4>
<div class="paragraph">
<p>With the exponential growth of machine learning and development of Artificial
Neural Network (ANNs) in recent years, there is great opportunity to leverage
this approach and accelarate biological discoveries through applications on the
analysis of high-throughput data.  Various types of datasets including for
example protein or gene interaction networks, molecular structures and cellular
signalling pathways, have already been used for machine learning by training
ANNs for inference and pattern classification.  However, unlike regular data
structures that are commonly used in the computer science and engineering
fields, bioinformatics datasets present challenges that require unique
algorithmic approaches.  The recent development of the geometric and deep
learning approach within the machine learning field, is very promising towards
accelerating analysis complex bioinformatics datasets.  The principles of ANNs
and their importance for bioinformatics machine learning is demonstrated
herein, through presentation of the undelying mathematical and statistical
foundations from group theory, symmetry, linear algebra.  Furthermore, the
structure and functions of ANN algorithms that form the core principles of
artificial intelligence are explained, in relation to the bioinformatics data
domain.  Overall, the manuscript provides guidance for researchers to
understand the principles required for practicing machine learning and
artificial intelligence, with the special considerations towards bioinformatics
applications.</p>
</div>
<div class="paragraph">
<p>*Keywords:*<em>machine learning, artificial intelligence, bioinformatics, cancer biology, neural networks, symmetry, group theory, algorithms</em></p>
</div>
</div>
<div class="sect3">
<h4 id="_simple_summary">SIMPLE SUMMARY</h4>
<div class="paragraph">
<p>The present manuscript provides an overview of the formalisms at the foundation
of Artificial Neural Networks (ANNs), that are the basis of Artificial
Intelligence within the broader field of Machine Learning.  The review is from
the perspective of bioinformatics data, and multiple examples of the
applications of the formalisms to experimental scenarios  are presented herein.
The mathematical formalisms are explained in detail, and biologists who are not
Machine Learning experts are provided with the opportunity to understand the
algorithmic basis of Artificial Intelligence towards bioinformatics
applications.</p>
</div>
</div>
<div class="sect3">
<h4 id="_introduction">INTRODUCTION</h4>
<div class="paragraph">
<p>In summary, Artificial Intelligence (AI), Machine Learning (ML), and Deep
Learning (DL) are related concepts with key differences: AI focuses on creating
machines that can perform tasks requiring human intelligence, ML enables
computers to learn from data and make predictions without explicit programming,
and DL uses deep neural networks to extract patterns from complex datasets. AI
encompasses ML and DL, which are subsets of AI. ML algorithms learn patterns
from data to make accurate predictions or decisions and can be categorized into
supervised, unsupervised, and reinforcement learning. DL algorithms, inspired
by the human brain, use deep neural networks to learn and extract patterns from
large-scale datasets. DL has had success in image and speech recognition,
natural language processing, and autonomous driving.</p>
</div>
<div class="paragraph">
<p>Symmetry and invariance is a central concept in physics, mathematical and
biological systems, and has been established since the early 20th century that
fundamental principles of nature are based on symmetry [<a href="#noether1918invariante">1</a>].
In the last decade, technologies such as genomic
sequencing have enabled an exponential increase [<a href="#katz2022sequence">2</a>] of the
data that describe the molecular elements, structure and function of biological
systems. Furthermore, data generation in fields as diverse as physics, software
development and social media [<a href="#clissa2022survey">3</a>], have resulted in datasets
of scale not previously available to scientists. This data abundance, has been
fundamental for the ever accelerating advancements in the field of machine
learning, deep learning and artificial intelligence, where we now  have
algorithms that can be trained to make discoveries from the data, at a level
that closely matches human intuition.</p>
</div>
<div class="paragraph">
<p>The field of deep learning and artificial intelligence, has developed rapidly
within the span of a few years, and while researchers have developed hundreds
of successful algorithms, there currently few unifying principles to organize
systematically the machine learning algorithms. In a seminal <code>proto-book</code> by
Bronstein et al.  [<a href="#bronstein2021geometric">4</a>], a range of systematization
principles for the different Artificial Neural Network (ANN) architectures and
deep learning algorithms were presented, based on the concepts of symmetry and
mathematical group theory.  The authors also introduced the concept of
geometric deep learning, and demonstrated how the group theory, function
invariance and equivariance principles, can be used as basis towards composing
and describing the various deep learning algorithms. Along these lines, in the
present manuscript we explain the structure of ANNs and the principles of machine
learning algorithms, while providing a review of mathematical and statistical
foundations related to the  development of artificial intelligence applications
with bioinformatics data.</p>
</div>
</div>
<div class="sect3">
<h4 id="_the_structure_of_artificial_intelligence_and_neural_networks">THE STRUCTURE OF ARTIFICIAL INTELLIGENCE AND NEURAL NETWORKS</h4>
<div class="paragraph">
<p>We will first describe the structures and function of deep learning and
Artificial Neural Networks (ANNs) that are the basis of artificial intelligence
[<a href="#li2019deep">5</a>]. Assume a dataset consisting of <em>n</em> pairs of
\$(x_i,y_i)_n\$, with the \$x_i\$ being <em>n</em> data points and \$y_i\$
their labels. Each \$x_i\$ data point can be for example be a number, a
vector (array of numbers), or a matrix (grid of numbers) storing different types
of bioinformatics data.  The labels can be of various formats, such as
binary (two-option) as for example \$y_i=1\$ "inhibits cancer growth", or
\$y_i=0\$ "does not inhibit cancer". The labels can also be continuous
numbers such as for example \$y_i=0.3\$ meaning 30% inhibition, or a
composite label such as \$y_i = (0,1,0)\$ representing respectively drug
attributes such as '0 - no inhibition', '1 - yes for toxicity', '0 - not
metabolized'. Similarly, the input data points can also be composite such as
for example \$x_i = (50,100)\$ representing two measuments for a single
biological entity. Independently of the label structure, the deep learning
algorithms and the overall goal of artificial intelligence applications for
bioinformatics, is to first train the ANN with data for which the labels are
known, and then perform classification of newly generated data, by predicting
their labels.</p>
</div>
<div class="paragraph">
<p>The simplest structure of an artificial neural network as shown on <strong>Fig.1</strong> is
"fully connected", with each neuron <em>k</em> in the ANN having a number of incoming
and outgoing connections corresponding to the number of neurons in previous and
next layer in the neural network. For example the neuron \$k_0^(1)\$ of the
<em>First Layer (1)</em> on <strong>Fig.1</strong>, has \$n = 2\$ incoming and \$n = 3\$
outgoing connections, corresponding respectively to the "input layer" with two
neurons, and three connections with the neurons of the internal ("hidden
layer") labeled <em>Second Layer (2)</em> on the figure. The internal layers are
called "hidden" since they do not receive input data directly, similarly to the
neurons performing cognition in animal brains, as opposed to sensory neurons.
While the hidden layers can have an arbitrary number of neurons based on the
complexity of the label classification problem we need the ANN to resolve
[<a href="#uzair2020effects">6</a>], the input layer has the exact number of neurons
corresponding to the input data structure. On <strong>Fig. 1</strong> for example we have two
input neurons, and the data can be of the form \$x_i = (50,100)\$. Finally,
the output layer has a number of neurons corresponding to the number of labels
\$y_i\$ per input data point in the data, and on <strong>Fig. 1</strong> there is a single
label.</p>
</div>
<div class="imageblock middle">
<div class="content">
<img src="Fig1.svg" alt="Fig1" width="778" height="484">
</div>
</div>
<hr>
<div class="paragraph">
<p><strong>Figure 1.</strong> An example <strong>Artificial Neural Network (ANN)</strong>. The signal
aggregation taking place on the second neuron \$sigma_(k_1^((2)))\$ of the
second hidden layer, can be expressed with the formula
\$sigma_(k_1^((2)))=sum_(k_(0,1,2))^((1)) w_(k0)**x_(k0) + w_(k1)**x_(k1) +
w_(k2)**x_(k2) - b\$, which is the aggregation of neuron signals from the first
layer, shown as red arrows on the figure. The <em>b</em> is the threshold that needs
to be overcome by the aggregation sum in order for the neuron to fire, and then
the neuron will transmit a signal along the line shown towards the output on
the final layer on the figure. The reader should refer to the text for more
details.</p>
</div>
<hr>
<div class="paragraph">
<p>Similar to neural networks in animal brains, the computational abstractions
used in machine learning and artificial intelligence, model neurons as
computational units performing signal summation and threshold activation.
Specifically, each artificial neuron performs a summation of incoming signals
from its connected neighbooring neurons in the preceeding layer on the network,
shown for example as red arrows on <strong>Fig.1</strong> for \$sigma_(k_1^((2)))\$. The
signal processing across the ANN transitions from input data \$x_i\$ on the
leftmost layer (<strong>Fig.1</strong>), to output of data labels \$y_i\$ on the right end.
Within each neuron, when the aggregated input reaches a certain threshold, the
neuron "fires" and transmits a signal to the next layer. The signals coming
into the neuron can be either the data directly from the input layer, or
signals generated by activation of the neurons in the intermediate - "hidden"
layers. The summation and thresholding computation within each neuron is
represented with the function \$sigma_(k)=sum_1^k w_(k)**x_(k) - b\$, where
the \$w_(k)\$ is the connection weights of the preceding neurons. Each
connection arrow on <strong>Fig.1</strong> has a different weight, such as for example
\$x_(k0)\$ which is the incoming signal from the neuron
\$sigma_(k_0^((1)))\$ to neuron \$sigma_(k_1^((2)))\$, multiplied by the
weight \$w_(k0)\$, which represents the strength of the connection between
these two artificial neurons.</p>
</div>
<div class="paragraph">
<p>The weights in artificial neural networks represent the strength of connections
between neurons. They determine the impact of input signals on the final output
of the network. During the training process, these weights are adjusted to
minimize the difference between the network&#8217;s predicted output and the desired
output. The weights essentially control the flow of information through the
network, allowing it to learn and make accurate predictions. Correctly tuned
weights are crucial for the network to effectively learn patterns and
generalize its knowledge to new input data.</p>
</div>
<div class="paragraph">
<p>For the majority of applications, the weight values \$w_(k)\$ are the only
elements in the ANN structure that are variable, and are adjusted by the
algorithms during training with the input data. This is similar to the
biological brain, where learning takes place by strengthening connections among
neurons [<a href="#wainberg2018deep">7</a>]. However, unlike the biological brain the ANNs
used in practice for data analysis have fixed connections between the neurons
and the structure of the neural network does not change during training and
learning to recognize and classify new data. The last term <em>b</em> in the
summation, represents a threshold that needs to be surpassed such as
\$sum_1^k w_(k)**x_(k) &gt; b\$, in order for the neuron to activate.  One
final step before the output value of the neuron is tranmitted, is the
application of a "logit" function to the summation value, that is represented
as \$varphi(sigma_(k))\$. The \$varphi\$ can be selected from a range of
non-linear functions depending on the the type of input data, and the specific
analysis and data classification domain for which the ANN will be used
[<a href="#li2019deep">5</a>]. The value of the logit function is the output of the neuron,
which is transmitted to its connected neurons in the next layer through the
outgoing connections, shown as an arrows on <strong>Fig.1</strong> and corresponding to the
brain cell axons in the biological analogy. Multiple layers of neurons
connected together in layers (<strong>Fig.1</strong>), along with multiple connections per
layer each having each own weight \$w_(k)\$, forms the Artificial Neural
Network (ANN).</p>
</div>
<div class="paragraph">
<p>From a mathematical formalism perspective, a trained ANN is a function \$f\$
that predicts labels \$y_(pred_i)\$ such as for example 'no inhibition',
'yes for toxicity' etc., for different types of input data \$x_i\$ ranging
from histology images to drug molecules represented as graph data structures.
Therefore, the ANN performs data classification as a mapping function
\$f(x_i)=y_(pred_i)\$, from the input data to the labels. Furthermore, the
\$f(x_i)\$ is a non-linear function, since it is an aggregate composition of
the non-linear functions \$varphi(sigma_(k))\$ of the individual
interconnected neurons in the network [<a href="#li2019deep">5</a>].  As a result, the
\$f(x_i)\$ can classify labels for data inputs that originate from complex
data distributions, and this fact enables ANNs to achieve higher analytical
power compared to typical statistical learning algorithms
[<a href="#tang2019recent">8</a>]. The \$f(x_i\$ is estimated by fitting a training
dataset, which correlates labels \$y_i\$ to data points \$x_i\$.  With
hundreds of papers and monographs that have been written on the technical
details of training ANNs, we will next attempt to briefly summarize the process
and refer the reader to the citations for further details.</p>
</div>
<div class="paragraph">
<p>As mentioned previously, the only variable element in the ANN structure are the
weights \$w_k\$ of the neuron connections, and therefore training an ANN to
classify data is the estimation of the weights. Furthermore, the training
process involves minimizing the error \$E\$, which is the difference between
the labels \$y_(pred_i)\$ predicted by the function \$f\$ and the true
labels \$y_i\$. This error metric is akin to true/false positive and
negatives (precision and recall) used in statistics, however diffent formulas
are used for its estimation for multi-label or complex input data to the ANN
(for more details, [<a href="#kriegeskorte2019neural">9</a>]). The neuron connection weight
\$w_k\$ estimation by the algorithm takes place by fitting the network
function \$f\$ on a large training dataset of \${x_i,y_i}_i^n\$ pairs of
input data and labels, while the error \$E\$ is calculated by using a subset
of the data for testing and validation.  The training algorithm starts with an
initial value of the weights, and then performs multiple cycles (called
"epochs") towards estimating the function \$f\$ by fitting the data
\$x_i\$ to the network and calculating the error \$E\$ by comparing
predicted \$y_(pred_i)\$ and the true labels \$y_i\$. At the end of each
cycle "backpropagation" is performed [<a href="#tang2019recent">8</a>], which involves a
gradient descent optimization algorithm, in order to fine tune the weights of
the individual neurons and minimize \$E\$.  The gradient descent
[<a href="#ruder2016overview">10</a>] searches the possible combinations of weight values,
and since it is a heuristic algorithm it minimizes \$E\$, but cannot reach
zero error. At the completion of multiple training cycles the training
algorithm identifies a set of weights which best fit the data, and the ANN
settles on the optimal values that estimate the \$varphi(sigma_(k))\$ function for
\$sigma_(k)=sum_1^k w_(k)**x_(k) - b\$, where \$w_(k)\$ is the weight in
each interconnected neuron. Consequently, the overall \$f\$ represented by
the network is also estimated,since as it was mentioned previously is the
composition of the individual \$varphi(sigma_(k))\$ neuron functions.  Once
the artificial neural network training has been completed by finding the most
optimal set of weights, it is now ready to be used for label prediction with
new, unknown \$x_i\$ data.</p>
</div>
</div>
<div class="sect3">
<h4 id="_artificial_intelligence_group_theory_symmetry_and_invariance">ARTIFICIAL INTELLIGENCE, GROUP THEORY, SYMMETRY AND INVARIANCE</h4>
<div class="paragraph">
<p>We conclude, by reviewing how the principles of group theory, symmetry and
invariance, provide a foundational framework to understand the function of
machine learning algorithms, and the classifying power of ANNs in relation to
statistical variance, transformations, and non-homogeneity in the input data.
In broad terms, symmetry is the analysis of geometric and algebraic
mathematical structures, and can have applications with data found in the
fields of physics, molecular biology and machine learning. A core concept in
symmetry is invariance, which in our context is changing data coordinates,
such as shifting a drug molecule in space or a cancer histology tissue sample,
while leaving the shape of the object unchanged [<a href="#bronstein2021geometric">4</a>].
Following such a change which as will be formally defined later in the text as
<em>invariant transformation</em>, the machine learning algorithms and ANNs must be able
to recognize a drug molecule following rotation, or a tissue to be recognized
as cancerous from a shifted histology image.</p>
</div>
<div class="paragraph">
<p>In order to link the abstract symmetry concepts with data classification in
machine learning, following the terminology of Bronstein et al., we consider
the input data \$x_i\$ to originate from a symmetry domain \$Omega\$. The
\$Omega\$ is the structure upon which the data are based, and upon the
domain structure we train the artificial neural networks to perform
classification, through the label prediction function \$f\$ as mentioned in
the earlier section. For example, microscopy images are essentially
2-dimensional numerical grids of <em>n x n</em> pixels (<strong>Fig.2a</strong>), with each pixel
having a value for the light intensity captured when the image was taken. In
this case the data domain is a grid of integers (\$ZZ\$), represented as
\$Omega: ZZ_n xx ZZ_n\$. Similarly, for color images the data domain is
\$x_i:Omega to ZZ_n^3 xx ZZ_n^3\$, with three overlayed integer grids each
representing the green, blue and red layers composing the color image. In
either case, the \$Omega\$ contains all possible combinations of pixel
intensities, while the specific pixel value combinations of the images in the
input data \$x_i\$  are a "signal" \$"X"(Omega)\$ from the domain.  The
ANN data classification and label prediction function \$y_(pred_i)=f(x_i)\$
is applied on the signal \$"X"(Omega)\$ which is essentially a subset of
the domain \$Omega\$.</p>
</div>
<div class="paragraph">
<p>A <em>symmetry group</em> \(G\) contains all possible transformations of the
input signal \$"X"(Omega)\$ called symmetries \(g\) or
otherwise <em>group actions</em>. A symmetry transformation \(g\) preserves
the properties of the data, such as for example not distorting the objects in
the image during rotation. The members of the symmetry group \(g \in
G\) are the associations of two or more coordinate points \(u,v\in \Omega\)
on the data domain (grid in our image example). Between these coordinates, the image can be rotated,
shifted or otherwise transformed without any distortion. Therefore, the key aspect
of the formal mathematical definition of the group, is that the data attributes
are preserved during object distortions that are common during the experimental
acquisition of bioinformatics data. The concept of symmetry groups is
important towards modeling the performance of machine learning algorithms, for
classifying the data patterns correctly, despite the variability found in the input data.</p>
</div>
<div class="imageblock left">
<div class="content">
<img src="Fig2a.svg" alt="Fig2a" width="315" height="262">
</div>
</div>
<div class="imageblock right">
<div class="content">
<img src="Fig2b.svg" alt="Fig2b" width="629" height="235">
</div>
</div>
<hr>
<div class="paragraph">
<p><strong>Figure 2. (a).</strong> A <em>grid</em> data structure representing image pixels, and
formally is a <em>graph</em> <strong>(b).</strong> A <em>graph</em> \(G = (V, E)\), is composed of
<em>nodes</em> \(V\) shown as circles, and <em>edges</em>  connecting the nodes and
shown as arrows. It can represent a protein, where the amino acids are the
nodes and the peptide bonds between amino acids are the edges.</p>
</div>
<hr>
<div class="paragraph">
<p>Another important data structure for bioinformatics is a <em>graph</em> \(G
= (V, E)\), composed of <em>nodes</em> \(V\) representing biological
entities, and <em>edges</em>  which are the connections between pairs of nodes
(<strong>Fig.2b</strong>).  In a specific instance of a graph for a real-world object,  the
edges are a subset of all possible links between nodes. An example graph data
structure for a biological molecule such a protein or a drug, would represent
the amino acids or atoms as node entities, and the chemical bonds between each
of these entities as edges. The edges can correspond to either the
carbonyl-amino (C-N) peptide bonds between amino acids and molecular
interactions across the peptide chain on the protein structure, or the chemical
bonds between atoms in a drug molecule. Furthermore, attributes in the
molecular data such as for example polarity and amino acid weight, or drug
binding properties can be represented as \(s\) - dimensional node
attributes, where <em>s</em> are the attributes assigned to each node.  Similarly, the
edges or even entire graphs can have attributes, for experimental data measured
on the molecular interactions represented by the edges, and measurements of the
properties of the complete protein or drug.  Finally, from an algorithmic
perspective , images are a special case of graphs where the nodes are the
pixels, and connect with edges in a structured pattern that form of a grid
(<strong>Fig.2a</strong>) representing the adjacent position of the pixels.</p>
</div>
<div class="paragraph">
<p>Having established the mathematical and algorithmic parallels between graphs
and images, we will now utilize the principles of the <em>symmetry group</em>
\(G\) to examine the analytical and classification power of machine
learning ANNs, in relation to variability and transformations in the data. For
both data types such as input images or molecules represented as graphs that
are shifted or rotated, we establish the concept of invariance through the
principles of group theory and symmetry. These are the foundational
mathematical and algorithmic formalisms, that can be used to model the
performance and output of machine learning algorithms ANNs in relation to the
variability in the dataset. Consecutively, these principles can then be
extrapolated and generalized for other types of data beyond graphs and images,
for which ANNs are trained for prediction and classification. While we present
the group and symmetry definitions following a data-centric approach, we will
nonetheless still follow the mathematical formalism, when describing how the
group operations can transform the input data. Furtermore, different types of
data can have the same symmetry group, and different transformations can be
performed by the same group operation. For example, an image with a triangle
which essentially is a graph with three nodes, can have the same rotational
symmetry group as a graph of three nodes or a numerical sequence of three
elements.</p>
</div>
<div class="paragraph">
<p>When chemical and biological molecules are represented as graphs as described
earlier, the nodes \(V\) can be in any order depending on how the
data were measured during the experiment.   This does not change the meaning of
the data, and as long as the edges <strong>E</strong> representing the connections between
the molecules are not modified, we have a proper representation of the
molecular entity independently of the ordering of <strong>V</strong>. In this case, where
two graphs for the same molecule have the same edges but different ordering of
nodes, they are called <em>isomorphic</em>. Any machine learning algorithm performing
pattern recognition on graphs, should not depend on the ordering of nodes so
that classification with ANNs and artificial intelligence is not affected by
experiment measurement variations in real-world data.  This is something that
is taken for granted with human intelligence, where for example we can
recognize an object even when a photograph is rotated at an angle. Returning to
our formal definitions, in order for ANNs algorithms to equivalently recognize
<em>isomorphic</em> graphs, the functions \$varphi(sigma_(k))\$ and overall
\$f(x_i)\$ of the ANN acting on graph data should be <em>permutation
invariant</em>.This means that for any permutation of the input dataset, the output
value of these functions are identical independently of the ordering of the
nodes <strong>V</strong> for example in the case of graphs. This concept can be similarly
applied to images, which as mentioned previously are special cases of fully
connected graphs, and furthermore these principles can also be generalized to
other data types beyond images or graphs.</p>
</div>
<div class="paragraph">
<p>In order to formalize further the concept of invariance, and since both
examples of the image and graphs are similarly points on a grids on a two
dimemensional plane, we can use linear algebra. Specifically, by using a matrix
we can represent the data transformations as group actions \(g\),
within the symmetry group \(G\). The use of matrices enables us to
connect the group symmetries with the actual data, through matrix
multiplications that modify the coordinates of the object and consecutively
represent the data transformations through the multiplication. The dimensions
of the matrix \(n \times n\) are usually similar to these of the
signal space \$"X"(Omega)\$ for the data (for example, \$ZZ_n xx ZZ_n\$ images).
The the matrix dimensions not depend on the size of the group i.e.  the number
of possible symmetries, or the dimensionality of underlying data domain
\(\Omega\). With this definition in place, we can formalize
symmetries and group actions for modifying data objects, and the use of matrix
and linear transformations as basis for connecting invariance in relation to
variability in the data.</p>
</div>
<div class="paragraph">
<p>We will now conclude by establishing the mathematical and linear algebra
formalisms, for resilience of the ANNs and machine learning algorithm pattern
recognition, in relation to transformations in the data. While our framework is
on a two-dimensional, grid data domain \(\Omega\), the formalisms
developed here can also be extrapolated without loss of generality to any
number of dimensions or data formats. We will first connect matrices to group
actions \(g\) (rotations, shifts etc.) in the symmetry group
\(g \in G\), by defining a function \(\theta\) that maps
the group to a matrix as \(\theta : G \rightarrow \mathbf{M}\). As
mentioned previously, a matrix  \(\mathbf{M} \in  R^{n \times n}\) of
numerical values (integers, fractions, positive and negative), when multiplied
to the coordinate values of an object on the plane \(\Omega\), it
rotates or shifts the object coordinates for the exact amount correponsing to
the group action within the symmetry group.</p>
</div>
<div class="paragraph">
<p>With these definitions in place, we will now connect the matrix formalisms with
the neural network estimator function \$y_(pred_i)=f(x_i)\$, that is
identified by adjusting neuron connection weights during multiple training
cycles with the input data.  Our goal is to leverage the mathematical
formalisms of group symmetry and invariance, in order to establish the ANN
resilience for classifying and assigning labels to new data points. The data
points originate from real-world data that might contain tranformations and
distortions. We first define that the estimator function of the ANN to be
<em>invariant</em>, if the condition for the input data holds such as
\(f(\mathbf{M} \times x_i) = f(x_i)\) for all matrices
\(\mathbf{M}\) representing the actions \(g \in G\) within
the symmetry group. This formula presents the condition required for the neural
network function to be invariant: its output value is the same whether the
input data \$x_i\$ are transformed or not (i.e an image or graph is not
rotated on the plane), as this is represented by the matrix multiplication
\(\mathbf{M} \times x_i\) . Therefore, the output values
\$y_(pred_i)=f(x_i)\$ by the ANN which are essentially predicted output
labels (i.e \$y_(pred_i)\$ = potent drug / not potent etc.) based on the
input data, are resilient to noisy and deformed real-world data, when the
network estimator function is invariant.  In a different case, the estimator
function approximated by the ANN can be <em>equivariant</em> and defined as
\(f(\mathbf{M} \times x_i) = \mathbf{M} \times f(x_i)\). This means
that the output of the ANN will be modified, but the label prediction result
will be equally shifted along with the shift in the input data.</p>
</div>
<div class="paragraph">
<p>Up to this point, we have discussed only discrete tranformations in linear
algebra terms, with matrix multiplications that result in a shift of
coordinates and rigid transformations of the data, such as a rotation of the
image or the graph by a specific angle on the grid \$Omega\$. However, we
can have also also have continuous, more fine grained shifts which is common
with real-world data. In this case, the ANNs algorithms should be able to
recognize patterns, classify and label the data without any loss of
performance. Mathematically, the continuous transformations follow equally with
the invariant and equivariant functions described earlier.  If for example the
domain \(\Omega\) contains data that have smooth transformations and
shifts, such as moving images (video) or shifts of molecules and graphs that
preserve <em>continuity</em> in a topological definition
[<a href="#sutherland2009introduction">11</a>], in this case we have a <em>homeomorphism</em>
instead of <em>invariance</em>.</p>
</div>
<div class="paragraph">
<p>Finally, if the rate of continuous transformation of the data is quantifiable,
meaning that the function \(\theta\) that maps the group to a matrix
is <em>differentiable</em>, then the members of the symmetry groups will be part of a
<em>diffeomorphism</em>. As it follows from the principles of calculus, in this case
infinitely multiple matrices \(f(\mathbf(M)\) will be needed to be
produced by \(\theta\) for the continuous change of the data
coordinates at every point. These differentiable data structures are common
with manifolds, which for example could be used to represent proteins in fine
detail. In this case the molecule would be represented as cloud with all atomic
forces around the structure, instead of the discrete data structure of nodes
and edges of a graph.  Finally, if the manifold structure includes also a
metric of <em>distance</em> between its points to further quantify the data
transformations, in this case we will have an <em>isometry</em> during the
transformation due to a group action from the symmetry group.</p>
</div>
</div>
<div class="sect3">
<h4 id="_applications_of_ai_in_bioinformatics">APPLICATIONS OF AI IN BIOINFORMATICS</h4>
<div class="paragraph">
<p>Artificial Intelligence (AI) and Deep Learning have emerged as a powerful tool
with diverse applications in the field of bioinformatics, and multiple research
studies have been reported in the literature
[<a href="#pmid37446831">12</a>, <a href="#pmid37189058">13</a>, <a href="#pmid37043378">14</a>], which showcase the potential of
the technology to revolutionize healthcare and life sciences.</p>
</div>
<div class="paragraph">
<p>One of the significant applications is drug discovery, as AI algorithms enable
the analysis of large datasets of chemical compounds, predicting their
effectiveness and safety [<a href="#pmid37479540">15</a>, <a href="#pmid37458097">16</a>, <a href="#pmid37454742">17</a>]. This
accelerates the drug discovery process by screening potential candidates and
optimizing their properties, leading to significant cost and time savings.</p>
</div>
<div class="paragraph">
<p>In the field of genomics AI algorithms have been applied to the analysis of DNA
sequencing and gene expression data, facilitating the identification of
disease-causing mutations and understanding genetic variations
[<a href="#pmid37453366">18</a>, <a href="#pmid37446311">19</a>, <a href="#pmid37386009">20</a>, <a href="#pmid37370847">21</a>]. Furthermore, genomic data
analysis with AI algorithms has resulted into insights aid in the development
of personalized medicine approaches, tailoring treatments to individual
patients.</p>
</div>
<div class="paragraph">
<p>Consecutively, precision medicine can benefit from AI, where by integratively
analyzing patient data, including genetic information, medical history, and
lifestyle factors, AI can predict drug responses, identify potential side
effects, and suggest optimal treatment options for individual patients. This
personalized approach has great promise to enhance patient care and treatment
outcomes, along with disease diagnosis enhanced by AI techniques such as
analysis through machine learning algorithms of medical images, including MRI
scans, X-rays, and histopathology images, of diseases like cancer
[<a href="#pmid37488621">22</a>, <a href="#pmid37478073">23</a>, <a href="#pmid37474003">24</a>, <a href="#pmid37449611">25</a>]. This assists pathologists and
radiologists in making accurate diagnoses, for early detection and diagnosis
and to improve patient outcomes.</p>
</div>
<div class="paragraph">
<p>AI can also play a significant role in the development of bioinformatics tools
and software through acceleration of code delopment for tools  for the analysis
and interpretation of biological data, such as sequence alignment, protein
structure prediction, and functional annotation
[<a href="#pmid37329982">26</a>, <a href="#pmid37463768">27</a>, <a href="#pmid37460991">28</a>].  Moreover, AI-powered natural
language processing techniques are used to analyze scientific literature,
patents, and clinical trial reports. This enables researchers to stay updated
with the latest discoveries and facilitates knowledge discovery in the field.</p>
</div>
<div class="paragraph">
<p>In the are of clinical trials machine learning algorithms can help analyze vast
amounts of clinical trial data, by improving the rates of success for new drugs
and treatment strategies for patients partipating in the trials
[<a href="#pmid37486997">29</a>, <a href="#pmid37483175">30</a>]. The algorithms can result in better
optimization of the clinical trial designs, reduction costs and overall
acceleration of the drug development pipelines [<a href="#pmid37479540">15</a>, <a href="#pmid37458097">16</a>].</p>
</div>
<div class="sect4">
<h5 id="_conclusion">CONCLUSION</h5>
<div class="paragraph">
<p>The accelerated developments in the fields of Machine Learning and Artificial
Intelligence in recent years, have also had significant impact in the field of
Bioinformatics. Due to the rapid developements, there has been diminished
opportunity to categorize the algorithms and their applications, along with
their perfomance with different types of bioinformatics data.  By leveraging
the symmetry and group theory mathematical formalisms, we can establish the
priciples of operation of Artificial Intelligence algorithms with
bioinformatics data and the directions for future development in the field.</p>
</div>
<div class="paragraph">
<p><strong>Funding Information:</strong> This work has been supported by Award Number U54
CA221704(5) From The National Cancer Institute.</p>
</div>
<div class="paragraph">
<p><strong>Author Contributions:</strong> K.Krampis wrote the manuscript and performed the
research. C. Wultch provided overview during the development of the rresearch
and the manuscrit. E.Ross, O.Ogunwobi, G. Ma and R. Mazumder contributed to the
development of the research and provided feedback during the development of the
manuscript.</p>
</div>
<div class="paragraph">
<p><strong>Conflict of Interest:</strong> The authors declare no conflicts of interest.</p>
</div>
<div class="paragraph">
<p><strong>Institutional Review Board Statement:</strong> Not Applicable.</p>
</div>
<div class="paragraph">
<p><strong>Informed Consent Statement:</strong> Not Applicable.</p>
</div>
<div class="paragraph">
<p><strong>Data Availability Statement:</strong> No data were generated as part of the present
review paper.</p>
</div>
<div class="paragraph">
<p><strong>Acknowledgments:</strong> The authors would like to thank their respective
institutions for supporting their scholarly work.</p>
</div>
<div class="paragraph">
<p><strong>Conflicts of Interest:</strong> The authors declare no conflict of interest.</p>
</div>
<div class="paragraph">
<p><a id="noether1918invariante"></a>[1] E. Noether, “Invariante variationsprobleme, math-phys,” <em>Klasse, pp235-257</em>, 1918.</p>
</div>
<div class="paragraph">
<p><a id="katz2022sequence"></a>[2] K. Katz, O. Shutov, R. Lapoint, M. Kimelman, J. R. Brister, and C. O’Sullivan, “The sequence read archive: a decade more of explosive growth,” <em>Nucleic acids research</em>, vol. 50, no. D1, pp. D387–D390, 2022.</p>
</div>
<div class="paragraph">
<p><a id="clissa2022survey"></a>[3] L. Clissa, “Survey of Big Data sizes in 2021.” 2022.</p>
</div>
<div class="paragraph">
<p><a id="bronstein2021geometric"></a>[4] M. M. Bronstein, J. Bruna, T. Cohen, and P. Veličković, “Geometric deep learning: Grids, groups, graphs, geodesics, and gauges,” <em>arXiv preprint arXiv:2104.13478</em>, 2021.</p>
</div>
<div class="paragraph">
<p><a id="li2019deep"></a>[5] Y. Li, C. Huang, L. Ding, Z. Li, Y. Pan, and X. Gao, “Deep learning in bioinformatics: Introduction, application, and perspective in the big data era,” <em>Methods</em>, vol. 166, pp. 4–21, 2019.</p>
</div>
<div class="paragraph">
<p><a id="uzair2020effects"></a>[6] M. Uzair and N. Jamil, “Effects of hidden layers on the efficiency of neural networks,” in <em>2020 IEEE 23rd international multitopic conference (INMIC)</em>, 2020, pp. 1–6.</p>
</div>
<div class="paragraph">
<p><a id="wainberg2018deep"></a>[7] M. Wainberg, D. Merico, A. Delong, and B. J. Frey, “Deep learning in biomedicine,” <em>Nature biotechnology</em>, vol. 36, no. 9, pp. 829–838, 2018.</p>
</div>
<div class="paragraph">
<p><a id="tang2019recent"></a>[8] B. Tang, Z. Pan, K. Yin, and A. Khateeb, “Recent advances of deep learning in bioinformatics and computational biology,” <em>Frontiers in genetics</em>, vol. 10, p. 214, 2019.</p>
</div>
<div class="paragraph">
<p><a id="kriegeskorte2019neural"></a>[9] N. Kriegeskorte and T. Golan, “Neural network models and deep learning,” <em>Current Biology</em>, vol. 29, no. 7, pp. R231–R236, 2019.</p>
</div>
<div class="paragraph">
<p><a id="ruder2016overview"></a>[10] S. Ruder, “An overview of gradient descent optimization algorithms,” <em>arXiv preprint arXiv:1609.04747</em>, 2016.</p>
</div>
<div class="paragraph">
<p><a id="sutherland2009introduction"></a>[11] W. A. Sutherland, <em>Introduction to metric and topological spaces</em>. Oxford University Press, 2009.</p>
</div>
<div class="paragraph">
<p><a id="pmid37446831"></a>[12] M. Lee, “Recent Advances in Deep Learning for Protein-Protein Interaction Analysis: A Comprehensive Review,” <em>Molecules</em>, vol. 28, no. 13, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37189058"></a>[13] M. Wysocka, O. Wysocki, M. Zufferey, D. Landers, and A. Freitas, “A systematic review of biologically-informed deep learning models for cancer: fundamental trends for encoding and interpreting oncology data,” <em>BMC Bioinformatics</em>, vol. 24, no. 1, p. 198, May 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37043378"></a>[14] B. Jahanyar, H. Tabatabaee, and A. Rowhanimanesh, “Harnessing Deep Learning for Omics in an Era of COVID-19,” <em>OMICS</em>, vol. 27, no. 4, pp. 141–152, Apr. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37479540"></a>[15] F. W. Pun, I. V. Ozerov, and A. Zhavoronkov, “AI-powered therapeutic target discovery,” <em>Trends Pharmacol Sci</em>, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37458097"></a>[16] G. Floresta, C. Zagni, V. Patamia, and A. Rescifina, “How can artificial intelligence be utilized for de novo drug design against COVID-19 (SARS-CoV-2)?,” <em>Expert Opin Drug Discov</em>, pp. 1–4, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37454742"></a>[17] Y. Zhou <em>et al.</em>, “Deep learning in preclinical antibody drug discovery and development,” <em>Methods</em>, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37453366"></a>[18] A. rez-Mena, E. n, M. J. Alvarez-Cubero, A. Anguita-Ruiz, L. J. Martinez-Gonzalez, and J. Alcala-Fdez, “Explainable artificial intelligence to predict and identify prostate cancer tissue by gene expression,” <em>Comput Methods Programs Biomed</em>, vol. 240, p. 107719, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37446311"></a>[19] W. Wei, Y. Li, and T. Huang, “Using Machine Learning Methods to Study Colorectal Cancer Tumor Micro-Environment and Its Biomarkers,” <em>Int J Mol Sci</em>, vol. 24, no. 13, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37386009"></a>[20] D. Shigemizu <em>et al.</em>, “Classification and deep-learning-based prediction of Alzheimer disease subtypes by using genomic data,” <em>Transl Psychiatry</em>, vol. 13, no. 1, p. 232, Jun. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37370847"></a>[21] Z. Mirza <em>et al.</em>, “Identification of Novel Diagnostic and Prognostic Gene Signature Biomarkers for Breast Cancer Using Artificial Intelligence and Machine Learning Assisted Transcriptomics Analysis,” <em>Cancers (Basel)</em>, vol. 15, no. 12, Jun. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37488621"></a>[22] R. Adam, K. Dell’Aquila, L. Hodges, T. Maldjian, and T. Q. Duong, “Deep learning applications to breast cancer detection by magnetic resonance imaging: a literature review,” <em>Breast Cancer Res</em>, vol. 25, no. 1, p. 87, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37478073"></a>[23] Y. Tong <em>et al.</em>, “Prediction of lymphoma response to CAR T cells by deep learning-based image analysis,” <em>PLoS One</em>, vol. 18, no. 7, p. e0282573, 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37474003"></a>[24] L. R. Archila <em>et al.</em>, “Performance of an Artificial Intelligence Model for Recognition and Quantitation of Histologic Features of Eosinophilic Esophagitis on Biopsy Samples,” <em>Mod Pathol</em>, p. 100285, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37449611"></a>[25] Q. Li, A. Sandoval, and B. Chen, “Advancing spinal cord injury research with optical clearing, light sheet microscopy, and artificial intelligence-based image analysis,” <em>Neural Regen Res</em>, vol. 18, no. 12, pp. 2661–2662, Dec. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37329982"></a>[26] M. Santorsola and F. Lescai, “The promise of explainable deep learning for omics data analysis: Adding new discovery tools to AI,” <em>N Biotechnol</em>, vol. 77, pp. 1–11, Jun. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37463768"></a>[27] B. Waissengrin <em>et al.</em>, “Artificial intelligence (AI) molecular analysis tool assists in rapid treatment decision in lung cancer: a case report,” <em>J Clin Pathol</em>, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37460991"></a>[28] F. Hosseini, F. Asadi, H. Emami, and M. Ebnali, “Machine learning applications for early detection of esophageal cancer: a systematic review,” <em>BMC Med Inform Decis Mak</em>, vol. 23, no. 1, p. 124, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37486997"></a>[29] S. M. Ahmed, R. V. Shivnaraine, and J. C. Wu, “FDA Modernization Act 2.0 Paves the Way to Computational Biology and Clinical Trials in a Dish,” <em>Circulation</em>, vol. 148, no. 4, pp. 309–311, Jul. 2023.</p>
</div>
<div class="paragraph">
<p><a id="pmid37483175"></a>[30] A. Aliper <em>et al.</em>, “Prediction of clinical trials outcomes based on target choice and clinical trial design with multi-modal artificial intelligence,” <em>Clin Pharmacol Ther</em>, Jul. 2023.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2023-07-25 21:22:28 +0200
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>